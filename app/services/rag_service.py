import google.generativeai as genai
from supabase import create_client
import os
from typing import List, Dict, Optional
from dotenv import load_dotenv
import time

load_dotenv()

class RAGService:
    def __init__(self):
        """Kh·ªüi t·∫°o RAG Service v·ªõi Gemini v√† Supabase"""
        # Configure Gemini
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
        self.embed_model = "models/text-embedding-004"
        self.gen_model = genai.GenerativeModel("models/gemini-2.5-flash")
        
        # Configure Supabase
        self.supabase = create_client(
            os.getenv("SUPABASE_URL"),
            os.getenv("SUPABASE_KEY")
        )
    
    def generate_embedding(self, text: str) -> List[float]:
        """
        T·∫°o embedding cho query c·ªßa user
        
        Args:
            text: C√¢u h·ªèi c·ªßa user
            
        Returns:
            Vector embedding 768 chi·ªÅu
        """
        result = genai.embed_content(
            model=self.embed_model,
            content=text,
            task_type="retrieval_query"
        )
        return result['embedding']
    
    def search_similar_documents(
        self, 
        query: str, 
        top_k: int = 3,
        similarity_threshold: float = 0.5
    ) -> List[Dict]:
        """
        T√¨m ki·∫øm documents t∆∞∆°ng t·ª± v·ªõi c√¢u h·ªèi
        
        Args:
            query: C√¢u h·ªèi c·ªßa user
            top_k: S·ªë l∆∞·ª£ng documents tr·∫£ v·ªÅ
            similarity_threshold: Ng∆∞·ª°ng similarity t·ªëi thi·ªÉu
            
        Returns:
            List c√°c documents li√™n quan nh·∫•t
        """
        try:
            # 1. T·∫°o embedding cho query
            query_embedding = self.generate_embedding(query)
            
            # 2. G·ªçi function match_documents trong Supabase
            result = self.supabase.rpc(
                "match_documents",
                {
                    "query_embedding": query_embedding,
                    "match_count": top_k
                }
            ).execute()
            
            # 3. Filter by similarity threshold
            filtered_docs = [
                doc for doc in result.data 
                if doc['similarity'] >= similarity_threshold
            ]
            
            return filtered_docs
            
        except Exception as e:
            print(f"‚ùå L·ªói khi search documents: {e}")
            return []
    
    def classify_question(self, question: str) -> str:
        """
        Ph√¢n lo·∫°i c√¢u h·ªèi ƒë·ªÉ x·ª≠ l√Ω ph√π h·ª£p
        
        Returns: 
            'barbergo_specific' - C√¢u h·ªèi v·ªÅ ch·ª©c nƒÉng app
            'beauty_related' - C√¢u h·ªèi v·ªÅ l√†m ƒë·∫πp, c·∫Øt t√≥c
            'greeting' - Ch√†o h·ªèi, x√£ giao
            'off_topic' - Ho√†n to√†n ngo√†i l·ªÅ
        """
        # Keywords v·ªÅ BarberGo app
        barbergo_keywords = [
            'ƒë·∫∑t l·ªãch', 'h·ªßy l·ªãch', 'app', '·ª©ng d·ª•ng', 'barbergo',
            'thanh to√°n', 'ƒë·ªëi t√°c', 't√†i kho·∫£n', 'm·∫≠t kh·∫©u', 'ƒëƒÉng k√Ω',
            'ƒëƒÉng nh·∫≠p', 'qu√™n m·∫≠t kh·∫©u', 'h·ªßy t√†i kho·∫£n', 'c√†i ƒë·∫∑t',
            'th√¥ng b√°o', '∆∞u ƒë√£i', 'khuy·∫øn m√£i', 'gi·∫£m gi√°'
        ]
        
        # Keywords v·ªÅ l√†m ƒë·∫πp
        beauty_keywords = [
            't√≥c', 'c·∫Øt', 'nhu·ªôm', 'u·ªën', 'du·ªói', 'g·ªôi', 'massage',
            'spa', 'nail', 'm√≥ng', 'l√†m ƒë·∫πp', 'chƒÉm s√≥c da', 'm·∫∑t',
            'wax', 'tri·ªát l√¥ng', 'facial', 'm·∫∑t n·∫°', 'th·ª£', 'salon',
            'barber', 't√≥c nam', 't√≥c n·ªØ', 'ki·ªÉu t√≥c', 'phong c√°ch'
        ]
        
        # Keywords ch√†o h·ªèi
        greeting_keywords = [
            'ch√†o', 'hello', 'hi', 'xin ch√†o', 'hey', 'h·∫ø l√¥',
            'kh·ªèe kh√¥ng', 'b·∫°n l√† ai', 'b·∫°n t√™n g√¨', 'c·∫£m ∆°n', 'thanks'
        ]
        
        question_lower = question.lower()
        
        # Check greeting
        if any(kw in question_lower for kw in greeting_keywords):
            return 'greeting'
        
        # Check BarberGo specific
        if any(kw in question_lower for kw in barbergo_keywords):
            return 'barbergo_specific'
        
        # Check beauty related
        if any(kw in question_lower for kw in beauty_keywords):
            return 'beauty_related'
        
        return 'off_topic'
    
    def generate_answer(
        self, 
        question: str, 
        contexts: List[Dict]
    ) -> str:
        """
        Generate c√¢u tr·∫£ l·ªùi d·ª±a tr√™n contexts t·ª´ knowledge base
        
        Args:
            question: C√¢u h·ªèi c·ªßa user
            contexts: C√°c documents li√™n quan
            
        Returns:
            C√¢u tr·∫£ l·ªùi t·ª´ Gemini
        """
        # N·∫øu c√≥ context v·ªõi similarity cao (>0.65), tr·∫£ l·ªùi t·ª´ knowledge base
        if contexts and len(contexts) > 0 and contexts[0]['similarity'] > 0.65:
            # Build context t·ª´ retrieved documents
            context_text = "\n\n".join([
                f"Th√¥ng tin {i+1}:\n{doc['metadata']['output']}"
                for i, doc in enumerate(contexts[:2])  # Ch·ªâ l·∫•y 2 contexts t·ªët nh·∫•t
            ])
            
            # T·∫°o prompt cho Gemini
            prompt = f"""B·∫°n l√† tr·ª£ l√Ω ·∫£o th√¥ng minh c·ªßa ·ª©ng d·ª•ng BarberGo - ·ª©ng d·ª•ng ƒë·∫∑t l·ªãch c·∫Øt t√≥c v√† c√°c d·ªãch v·ª• l√†m ƒë·∫πp t·∫°i Vi·ªát Nam.

TH√îNG TIN T·ª™ KNOWLEDGE BASE:
{context_text}

C√ÇU H·ªéI C·ª¶A KH√ÅCH H√ÄNG:
{question}

H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
1. D·ª±a v√†o th√¥ng tin t·ª´ knowledge base ƒë·ªÉ tr·∫£ l·ªùi
2. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng (2-4 c√¢u)
3. Gi·ªçng ƒëi·ªáu th√¢n thi·ªán, chuy√™n nghi·ªáp
4. N·∫øu c√≥ nhi·ªÅu b∆∞·ªõc, li·ªát k√™ r√µ r√†ng
5. Tr·∫£ l·ªùi tr·ª±c ti·∫øp, kh√¥ng n√≥i "D·ª±a v√†o th√¥ng tin..."

C√ÇU TR·∫¢ L·ªúI:"""
            
            try:
                time.sleep(0.5)  # Rate limiting
                response = self.gen_model.generate_content(prompt)
                return response.text
            except Exception as e:
                print(f"‚ùå L·ªói khi generate answer: {e}")
                # Fallback: tr·∫£ v·ªÅ answer t·ª´ database
                return contexts[0]['metadata']['output']
        
        # Kh√¥ng c√≥ context ph√π h·ª£p -> x·ª≠ l√Ω theo lo·∫°i c√¢u h·ªèi
        return self._generate_fallback_answer(question)
    
    def _generate_fallback_answer(self, question: str) -> str:
        """
        Generate c√¢u tr·∫£ l·ªùi khi kh√¥ng t√¨m th·∫•y context ph√π h·ª£p
        X·ª≠ l√Ω th√¥ng minh d·ª±a tr√™n lo·∫°i c√¢u h·ªèi
        """
        question_type = self.classify_question(question)
        
        # 1. Ch√†o h·ªèi, x√£ giao
        if question_type == 'greeting':
            prompt = f"""B·∫°n l√† tr·ª£ l√Ω ·∫£o th√¢n thi·ªán c·ªßa BarberGo - app ƒë·∫∑t l·ªãch c·∫Øt t√≥c.

Kh√°ch h√†ng n√≥i: {question}

H√£y:
1. Tr·∫£ l·ªùi th√¢n thi·ªán, t·ª± nhi√™n
2. Gi·ªõi thi·ªáu ng·∫Øn g·ªçn b·∫°n c√≥ th·ªÉ gi√∫p g√¨ (v·ªÅ ƒë·∫∑t l·ªãch, d·ªãch v·ª• l√†m ƒë·∫πp)
3. Ng·∫Øn g·ªçn 2-3 c√¢u

V√ç D·ª§:
- "Ch√†o b·∫°n! M√¨nh l√† tr·ª£ l√Ω ·∫£o c·ªßa BarberGo. M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n ƒë·∫∑t l·ªãch c·∫Øt t√≥c, t√¨m salon g·∫ßn nh√†, ho·∫∑c gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ d·ªãch v·ª•. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ kh√¥ng?"

C√ÇU TR·∫¢ L·ªúI:"""
        
        # 2. C√¢u h·ªèi v·ªÅ l√†m ƒë·∫πp chung (kh√¥ng c√≥ trong DB)
        elif question_type == 'beauty_related':
            prompt = f"""B·∫°n l√† chuy√™n gia l√†m ƒë·∫πp c·ªßa ·ª©ng d·ª•ng BarberGo.

C√¢u h·ªèi v·ªÅ l√†m ƒë·∫πp: {question}

H√£y:
1. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, h·ªØu √≠ch d·ª±a tr√™n ki·∫øn th·ª©c chung v·ªÅ l√†m ƒë·∫πp (2-3 c√¢u)
2. G·ª£i √Ω ƒë·∫∑t l·ªãch tr√™n BarberGo ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n tr·ª±c ti·∫øp
3. Gi·ªçng ƒëi·ªáu th√¢n thi·ªán, chuy√™n nghi·ªáp

V√ç D·ª§:
- C√¢u h·ªèi: "T√≥c d√†i bao l√¢u n√™n c·∫Øt?"
- Tr·∫£ l·ªùi: "Th√¥ng th∆∞·ªùng n√™n c·∫Øt t√≥c 4-6 tu·∫ßn m·ªôt l·∫ßn ƒë·ªÉ gi·ªØ ki·ªÉu ƒë·∫πp v√† lo·∫°i b·ªè ng·ªçn t√≥c h∆∞ t·ªïn. B·∫°n c√≥ th·ªÉ ƒë·∫∑t l·ªãch v·ªõi stylist tr√™n BarberGo ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n c·ª• th·ªÉ d·ª±a tr√™n ki·ªÉu t√≥c v√† t√¨nh tr·∫°ng t√≥c c·ªßa m√¨nh nh√©!"

C√ÇU TR·∫¢ L·ªúI:"""
        
        # 3. C√¢u h·ªèi v·ªÅ BarberGo nh∆∞ng kh√¥ng c√≥ trong DB
        elif question_type == 'barbergo_specific':
            prompt = f"""B·∫°n l√† tr·ª£ l√Ω c·ªßa BarberGo.

Kh√°ch h√†ng h·ªèi v·ªÅ t√≠nh nƒÉng app: {question}

B·∫°n kh√¥ng c√≥ th√¥ng tin c·ª• th·ªÉ trong h·ªá th·ªëng. H√£y:
1. Xin l·ªói l·ªãch s·ª±
2. G·ª£i √Ω li√™n h·ªá b·ªô ph·∫≠n h·ªó tr·ª£ (chat trong app ho·∫∑c hotline)
3. Ng·∫Øn g·ªçn 2 c√¢u

C√ÇU TR·∫¢ L·ªúI:"""
        
        # 4. Ho√†n to√†n ngo√†i l·ªÅ
        else:  # off_topic
            prompt = f"""B·∫°n l√† tr·ª£ l√Ω c·ªßa BarberGo - app ƒë·∫∑t l·ªãch l√†m ƒë·∫πp.

Kh√°ch h√†ng h·ªèi: {question}

C√¢u h·ªèi n√†y KH√îNG li√™n quan ƒë·∫øn l√†m ƒë·∫πp ho·∫∑c BarberGo. H√£y:
1. L·ªãch s·ª± t·ª´ ch·ªëi (kh√¥ng tr·∫£ l·ªùi c√¢u h·ªèi off-topic)
2. Nh·∫Øc b·∫°n ch·ªâ h·ªó tr·ª£ v·ªÅ ƒë·∫∑t l·ªãch v√† d·ªãch v·ª• l√†m ƒë·∫πp
3. H·ªèi xem c√≥ th·ªÉ gi√∫p g√¨ v·ªÅ ch·ªß ƒë·ªÅ n√†y
4. Ng·∫Øn g·ªçn, th√¢n thi·ªán (2 c√¢u)

V√ç D·ª§:
- "T√¥i l√† tr·ª£ l√Ω chuy√™n v·ªÅ ƒë·∫∑t l·ªãch c·∫Øt t√≥c v√† d·ªãch v·ª• l√†m ƒë·∫πp n√™n kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y ƒë∆∞·ª£c. B·∫°n c√≥ c·∫ßn h·ªó tr·ª£ g√¨ v·ªÅ BarberGo kh√¥ng? üòä"

C√ÇU TR·∫¢ L·ªúI:"""
        
        try:
            time.sleep(0.5)  # Rate limiting
            response = self.gen_model.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"‚ùå L·ªói fallback: {e}")
            
            # Hard fallback d·ª±a tr√™n lo·∫°i
            fallback_responses = {
                'greeting': "Ch√†o b·∫°n! M√¨nh l√† tr·ª£ l√Ω ·∫£o c·ªßa BarberGo. M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n ƒë·∫∑t l·ªãch c·∫Øt t√≥c, t√¨m salon, ho·∫∑c gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ d·ªãch v·ª•. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ kh√¥ng?",
                'beauty_related': "M√¨nh nghƒ© b·∫°n n√™n tham kh·∫£o √Ω ki·∫øn stylist chuy√™n nghi·ªáp. B·∫°n c√≥ th·ªÉ ƒë·∫∑t l·ªãch t∆∞ v·∫•n mi·ªÖn ph√≠ tr√™n BarberGo ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ t·ªët nh·∫•t nh√©!",
                'barbergo_specific': "M√¨nh kh√¥ng c√≥ th√¥ng tin c·ª• th·ªÉ v·ªÅ c√¢u h·ªèi n√†y. B·∫°n vui l√≤ng li√™n h·ªá b·ªô ph·∫≠n h·ªó tr·ª£ qua chat trong app ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt h∆°n nh√©!",
                'off_topic': "T√¥i l√† tr·ª£ l√Ω chuy√™n v·ªÅ ƒë·∫∑t l·ªãch c·∫Øt t√≥c v√† d·ªãch v·ª• l√†m ƒë·∫πp. B·∫°n c√≥ c√¢u h·ªèi n√†o v·ªÅ BarberGo kh√¥ng? üòä"
            }
            return fallback_responses.get(question_type, fallback_responses['off_topic'])
    
    def query(
        self, 
        question: str, 
        top_k: int = 3,
        return_sources: bool = False
    ) -> Dict:
        """
        Main function ƒë·ªÉ query RAG system
        
        Args:
            question: C√¢u h·ªèi c·ªßa user
            top_k: S·ªë l∆∞·ª£ng contexts ƒë·ªÉ retrieve
            return_sources: C√≥ tr·∫£ v·ªÅ sources kh√¥ng
            
        Returns:
            Dict ch·ª©a answer v√† sources (n·∫øu c√≥)
        """
        # 1. Retrieve relevant documents
        relevant_docs = self.search_similar_documents(question, top_k)
        
        # 2. Generate answer
        answer = self.generate_answer(question, relevant_docs)
        
        # 3. X√°c ƒë·ªãnh confidence
        if relevant_docs and len(relevant_docs) > 0:
            max_similarity = relevant_docs[0]['similarity']
            if max_similarity > 0.75:
                confidence = "high"
            elif max_similarity > 0.5:
                confidence = "medium"
            else:
                confidence = "low"
        else:
            # Kh√¥ng c√≥ docs -> c√¢u h·ªèi ngo√†i l·ªÅ
            question_type = self.classify_question(question)
            confidence = "medium" if question_type in ['greeting', 'beauty_related'] else "low"
        
        # 4. Prepare response
        response = {
            "answer": answer,
            "confidence": confidence
        }
        
        if return_sources:
            response["sources"] = [
                {
                    "question": doc['metadata']['input'],
                    "answer": doc['metadata']['output'],
                    "similarity": round(doc['similarity'], 3)
                }
                for doc in relevant_docs
            ] if relevant_docs else []
        
        return response


# Singleton instance
rag_service = RAGService()