import os
from dotenv import load_dotenv
import google.generativeai as genai
from supabase import create_client

load_dotenv()

# Configure
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
supabase = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_KEY")
)

print("=" * 60)
print("üîç RAG SYSTEM DEBUG")
print("=" * 60)

# Test 1: Embedding
print("\n1Ô∏è‚É£ Test Embedding...")
try:
    question = "L√†m th·∫ø n√†o ƒë·ªÉ ƒë·∫∑t l·ªãch?"
    result = genai.embed_content(
        model="models/text-embedding-004",
        content=question,
        task_type="retrieval_query"
    )
    embedding = result['embedding']
    print(f"   ‚úÖ Embedding OK - dimension: {len(embedding)}")
except Exception as e:
    print(f"   ‚ùå Embedding Error: {e}")
    exit(1)

# Test 2: Supabase Search
print("\n2Ô∏è‚É£ Test Supabase Search...")
try:
    search_result = supabase.rpc(
        "match_documents",
        {
            "query_embedding": embedding,
            "match_count": 3
        }
    ).execute()
    
    docs = search_result.data
    print(f"   ‚úÖ Search OK - found {len(docs)} documents")
    
    if len(docs) > 0:
        print(f"\n   üìÑ Top result:")
        print(f"      Similarity: {docs[0]['similarity']:.3f}")
        print(f"      Question: {docs[0]['metadata']['input'][:80]}...")
        print(f"      Answer: {docs[0]['metadata']['output'][:80]}...")
    else:
        print("   ‚ö†Ô∏è No documents found!")
        
except Exception as e:
    print(f"   ‚ùå Supabase Error: {e}")
    exit(1)

# Test 3: Gemini Generate Content
print("\n3Ô∏è‚É£ Test Gemini Generation...")
try:
    # Simple test first
    model = genai.GenerativeModel("gemini-2.0-flash-exp")
    simple_response = model.generate_content("Say hello in Vietnamese")
    print(f"   ‚úÖ Simple generation OK: {simple_response.text[:50]}...")
    
except Exception as e:
    print(f"   ‚ùå Simple generation error: {e}")
    print("\n   Trying with gemini-1.5-flash instead...")
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        simple_response = model.generate_content("Say hello")
        print(f"   ‚úÖ Works with gemini-1.5-flash: {simple_response.text[:50]}...")
        print("\n   üí° Solution: Change model to 'gemini-1.5-flash' in rag_service.py")
    except Exception as e2:
        print(f"   ‚ùå Still error: {e2}")
        exit(1)

# Test 4: Generate with Context
print("\n4Ô∏è‚É£ Test Generation with Context...")
try:
    if len(docs) > 0:
        context = docs[0]['metadata']['output']
        prompt = f"""B·∫°n l√† tr·ª£ l√Ω ·∫£o c·ªßa BarberGo.

D·ª±a v√†o th√¥ng tin sau:
{context}

Tr·∫£ l·ªùi c√¢u h·ªèi: {question}

C√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn:"""

        response = model.generate_content(prompt)
        print(f"   ‚úÖ Context generation OK!")
        print(f"\n   üìù Answer: {response.text}")
        
except Exception as e:
    print(f"   ‚ùå Context generation error: {e}")
    print(f"\n   Error type: {type(e).__name__}")
    
    # Chi ti·∫øt l·ªói
    import traceback
    print("\n   Full traceback:")
    traceback.print_exc()

print("\n" + "=" * 60)
print("‚úÖ Debug complete!")
print("=" * 60)